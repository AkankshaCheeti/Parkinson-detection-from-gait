{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 181.1187 - accuracy: 0.6389 - val_loss: 71.3951 - val_accuracy: 0.6296\n",
      "Epoch 2/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 135.7321 - accuracy: 0.5463 - val_loss: 55.3391 - val_accuracy: 0.6296\n",
      "Epoch 3/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 116.4228 - accuracy: 0.5278 - val_loss: 51.0011 - val_accuracy: 0.7593\n",
      "Epoch 4/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 99.5521 - accuracy: 0.6111 - val_loss: 52.0099 - val_accuracy: 0.7222\n",
      "Epoch 5/40\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 76.6785 - accuracy: 0.6157 - val_loss: 37.6700 - val_accuracy: 0.7407\n",
      "Epoch 6/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 75.9782 - accuracy: 0.5787 - val_loss: 38.7264 - val_accuracy: 0.7778\n",
      "Epoch 7/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 76.1315 - accuracy: 0.5231 - val_loss: 37.2143 - val_accuracy: 0.7222\n",
      "Epoch 8/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 76.9475 - accuracy: 0.5648 - val_loss: 36.8382 - val_accuracy: 0.7222\n",
      "Epoch 9/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 77.9084 - accuracy: 0.5139 - val_loss: 33.8298 - val_accuracy: 0.6852\n",
      "Epoch 10/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 56.6323 - accuracy: 0.5556 - val_loss: 34.9475 - val_accuracy: 0.6481\n",
      "Epoch 11/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 46.6447 - accuracy: 0.5833 - val_loss: 36.7546 - val_accuracy: 0.6111\n",
      "Epoch 12/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 49.2967 - accuracy: 0.5741 - val_loss: 33.7306 - val_accuracy: 0.6296\n",
      "Epoch 13/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 45.4953 - accuracy: 0.6065 - val_loss: 30.4794 - val_accuracy: 0.5370\n",
      "Epoch 14/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 45.3386 - accuracy: 0.5417 - val_loss: 31.0392 - val_accuracy: 0.6481\n",
      "Epoch 15/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 53.9664 - accuracy: 0.4722 - val_loss: 40.3236 - val_accuracy: 0.4630\n",
      "Epoch 16/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 35.0441 - accuracy: 0.6065 - val_loss: 34.3044 - val_accuracy: 0.5370\n",
      "Epoch 17/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 57.7436 - accuracy: 0.4861 - val_loss: 32.0252 - val_accuracy: 0.6852\n",
      "Epoch 18/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 38.3545 - accuracy: 0.5926 - val_loss: 32.7337 - val_accuracy: 0.5741\n",
      "Epoch 19/40\n",
      "27/27 [==============================] - 0s 988us/step - loss: 56.7682 - accuracy: 0.5324 - val_loss: 27.4399 - val_accuracy: 0.7037\n",
      "Epoch 20/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 32.2545 - accuracy: 0.5787 - val_loss: 32.3949 - val_accuracy: 0.5926\n",
      "Epoch 21/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 39.2987 - accuracy: 0.5231 - val_loss: 28.1077 - val_accuracy: 0.7593\n",
      "Epoch 22/40\n",
      "27/27 [==============================] - 0s 995us/step - loss: 35.4481 - accuracy: 0.6250 - val_loss: 22.0028 - val_accuracy: 0.6852\n",
      "Epoch 23/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 47.9719 - accuracy: 0.5417 - val_loss: 37.6228 - val_accuracy: 0.7778\n",
      "Epoch 24/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 34.6588 - accuracy: 0.6204 - val_loss: 32.7250 - val_accuracy: 0.6111\n",
      "Epoch 25/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 46.7184 - accuracy: 0.4491 - val_loss: 35.6979 - val_accuracy: 0.7593\n",
      "Epoch 26/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 32.3326 - accuracy: 0.6065 - val_loss: 39.9860 - val_accuracy: 0.5556\n",
      "Epoch 27/40\n",
      "27/27 [==============================] - 0s 989us/step - loss: 35.3342 - accuracy: 0.5185 - val_loss: 35.5009 - val_accuracy: 0.6667\n",
      "Epoch 28/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 32.8235 - accuracy: 0.6435 - val_loss: 37.5900 - val_accuracy: 0.5556\n",
      "Epoch 29/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 35.0057 - accuracy: 0.5139 - val_loss: 32.3873 - val_accuracy: 0.5370\n",
      "Epoch 30/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 25.9326 - accuracy: 0.5509 - val_loss: 34.8553 - val_accuracy: 0.5370\n",
      "Epoch 31/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 32.8424 - accuracy: 0.5972 - val_loss: 31.0664 - val_accuracy: 0.6481\n",
      "Epoch 32/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 34.2528 - accuracy: 0.5602 - val_loss: 31.8402 - val_accuracy: 0.6667\n",
      "Epoch 33/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 29.6498 - accuracy: 0.5880 - val_loss: 30.7938 - val_accuracy: 0.5556\n",
      "Epoch 34/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 36.0076 - accuracy: 0.5972 - val_loss: 33.1469 - val_accuracy: 0.7593\n",
      "Epoch 35/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 30.1500 - accuracy: 0.5602 - val_loss: 31.7877 - val_accuracy: 0.5556\n",
      "Epoch 36/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 29.0442 - accuracy: 0.5417 - val_loss: 29.8943 - val_accuracy: 0.6111\n",
      "Epoch 37/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 36.1685 - accuracy: 0.5694 - val_loss: 34.3668 - val_accuracy: 0.5185\n",
      "Epoch 38/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 27.6196 - accuracy: 0.5556 - val_loss: 29.7119 - val_accuracy: 0.6481\n",
      "Epoch 39/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 34.6713 - accuracy: 0.5278 - val_loss: 28.6663 - val_accuracy: 0.6481\n",
      "Epoch 40/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 36.3289 - accuracy: 0.5833 - val_loss: 29.0659 - val_accuracy: 0.6111\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.8671 - accuracy: 0.7593\n",
      "Test accuracy: 0.7592592835426331\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and prepare the datasets\n",
    "data1 = pd.read_csv(\"../dataset/processed_data/Parkinson_CV_ensemble.tab\", delimiter=\"\\t\")\n",
    "data2 = pd.read_csv(\"../dataset/processed_data/Parkinson_FD_ensemble_pca.tab\", delimiter=\"\\t\")\n",
    "\n",
    "# Filter the last column as the label\n",
    "label1 = data1.iloc[:, -1]\n",
    "label2 = data2.iloc[:, -1]\n",
    "label1 = label1.replace({'Co': 0, 'Pt': 1})\n",
    "label2 = label2.replace({'Co': 0, 'Pt': 1})\n",
    "\n",
    "# Remove the last column from the datasets\n",
    "data1 = data1.iloc[:, :-1]\n",
    "data2 = data2.iloc[:, :-1]\n",
    "\n",
    "# Combine the datasets and labels\n",
    "data = pd.concat([data1, data2], axis=1)\n",
    "label = label1\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (X_train.shape[1],)\n",
    "\n",
    "# Define the attention mechanism layer\n",
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, features, hidden):\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "\n",
    "        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
    "\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "# Define the model architecture with attention mechanism\n",
    "def create_model(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(inputs)\n",
    "    hidden = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "    context_vector, attention_weights = Attention(32)(x, hidden)\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid')(context_vector)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "model = create_model(input_shape)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=40, batch_size=8, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the test accuracy\n",
    "print('Test accuracy:', accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 143.9862 - accuracy: 0.5139 - val_loss: 82.7637 - val_accuracy: 0.5926\n",
      "Epoch 2/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 90.7458 - accuracy: 0.5648 - val_loss: 67.6035 - val_accuracy: 0.5741\n",
      "Epoch 3/40\n",
      "27/27 [==============================] - 0s 968us/step - loss: 69.0181 - accuracy: 0.5556 - val_loss: 65.1301 - val_accuracy: 0.6111\n",
      "Epoch 4/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 56.8428 - accuracy: 0.5417 - val_loss: 64.4019 - val_accuracy: 0.6111\n",
      "Epoch 5/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 76.7579 - accuracy: 0.5417 - val_loss: 59.6829 - val_accuracy: 0.5741\n",
      "Epoch 6/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 56.0320 - accuracy: 0.5694 - val_loss: 57.7542 - val_accuracy: 0.6296\n",
      "Epoch 7/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 55.1356 - accuracy: 0.5602 - val_loss: 58.3745 - val_accuracy: 0.5185\n",
      "Epoch 8/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 51.2221 - accuracy: 0.5370 - val_loss: 47.6797 - val_accuracy: 0.5926\n",
      "Epoch 9/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 60.3271 - accuracy: 0.5972 - val_loss: 45.0307 - val_accuracy: 0.6296\n",
      "Epoch 10/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 52.8812 - accuracy: 0.5463 - val_loss: 51.1187 - val_accuracy: 0.5926\n",
      "Epoch 11/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 38.8130 - accuracy: 0.5324 - val_loss: 46.7660 - val_accuracy: 0.6667\n",
      "Epoch 12/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 49.8526 - accuracy: 0.5602 - val_loss: 50.0838 - val_accuracy: 0.5556\n",
      "Epoch 13/40\n",
      "27/27 [==============================] - 0s 999us/step - loss: 37.5228 - accuracy: 0.5556 - val_loss: 53.3428 - val_accuracy: 0.5185\n",
      "Epoch 14/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 29.5759 - accuracy: 0.6157 - val_loss: 51.4556 - val_accuracy: 0.5556\n",
      "Epoch 15/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 37.5399 - accuracy: 0.5880 - val_loss: 53.3977 - val_accuracy: 0.5741\n",
      "Epoch 16/40\n",
      "27/27 [==============================] - 0s 995us/step - loss: 36.3843 - accuracy: 0.6019 - val_loss: 50.0035 - val_accuracy: 0.6111\n",
      "Epoch 17/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 44.0701 - accuracy: 0.5093 - val_loss: 46.3890 - val_accuracy: 0.5926\n",
      "Epoch 18/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 33.3535 - accuracy: 0.5602 - val_loss: 49.3850 - val_accuracy: 0.5370\n",
      "Epoch 19/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 33.3233 - accuracy: 0.6019 - val_loss: 40.1957 - val_accuracy: 0.5926\n",
      "Epoch 20/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 34.2032 - accuracy: 0.5370 - val_loss: 48.5845 - val_accuracy: 0.5000\n",
      "Epoch 21/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 30.7346 - accuracy: 0.5602 - val_loss: 49.2812 - val_accuracy: 0.4815\n",
      "Epoch 22/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 32.5399 - accuracy: 0.5139 - val_loss: 46.0361 - val_accuracy: 0.5741\n",
      "Epoch 23/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 24.1655 - accuracy: 0.6620 - val_loss: 43.2029 - val_accuracy: 0.5370\n",
      "Epoch 24/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 27.9020 - accuracy: 0.5139 - val_loss: 39.8886 - val_accuracy: 0.5556\n",
      "Epoch 25/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 37.8191 - accuracy: 0.5463 - val_loss: 35.6481 - val_accuracy: 0.6111\n",
      "Epoch 26/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 30.0208 - accuracy: 0.5509 - val_loss: 34.7256 - val_accuracy: 0.5556\n",
      "Epoch 27/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 23.9067 - accuracy: 0.5463 - val_loss: 32.5344 - val_accuracy: 0.5741\n",
      "Epoch 28/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 21.8409 - accuracy: 0.6435 - val_loss: 28.1778 - val_accuracy: 0.5926\n",
      "Epoch 29/40\n",
      "27/27 [==============================] - 0s 982us/step - loss: 22.3456 - accuracy: 0.5880 - val_loss: 31.4468 - val_accuracy: 0.6296\n",
      "Epoch 30/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 19.0401 - accuracy: 0.5694 - val_loss: 36.3425 - val_accuracy: 0.5556\n",
      "Epoch 31/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 26.9323 - accuracy: 0.5324 - val_loss: 29.9498 - val_accuracy: 0.6481\n",
      "Epoch 32/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 26.7304 - accuracy: 0.6019 - val_loss: 39.7019 - val_accuracy: 0.4259\n",
      "Epoch 33/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 23.0638 - accuracy: 0.5972 - val_loss: 36.6765 - val_accuracy: 0.4630\n",
      "Epoch 34/40\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 18.8497 - accuracy: 0.5694 - val_loss: 29.5976 - val_accuracy: 0.6111\n",
      "Epoch 35/40\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 19.1337 - accuracy: 0.5324 - val_loss: 28.5171 - val_accuracy: 0.5556\n",
      "Epoch 36/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 14.9618 - accuracy: 0.6204 - val_loss: 30.1953 - val_accuracy: 0.5741\n",
      "Epoch 37/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 23.1288 - accuracy: 0.5370 - val_loss: 30.2163 - val_accuracy: 0.5370\n",
      "Epoch 38/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 16.3801 - accuracy: 0.6204 - val_loss: 26.3620 - val_accuracy: 0.5000\n",
      "Epoch 39/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 24.0004 - accuracy: 0.5694 - val_loss: 21.2329 - val_accuracy: 0.6481\n",
      "Epoch 40/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 19.8335 - accuracy: 0.5509 - val_loss: 22.1132 - val_accuracy: 0.5370\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.3869 - accuracy: 0.6667\n",
      "Test accuracy: 0.6666666865348816\n"
     ]
    }
   ],
   "source": [
    "#side only\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and prepare the datasets\n",
    "data1 = pd.read_csv(\"../dataset/processed_data/Parkinson_CV_ensemble_sideonly.tab\", delimiter=\"\\t\")\n",
    "data2 = pd.read_csv(\"../dataset/processed_data/Parkinson_FD_ensemble_pca_sideonly.tab\", delimiter=\"\\t\")\n",
    "\n",
    "# Filter the last column as the label\n",
    "label1 = data1.iloc[:, -1]\n",
    "label2 = data2.iloc[:, -1]\n",
    "label1 = label1.replace({'Co': 0, 'Pt': 1})\n",
    "label2 = label2.replace({'Co': 0, 'Pt': 1})\n",
    "\n",
    "# Remove the last column from the datasets\n",
    "data1 = data1.iloc[:, :-1]\n",
    "data2 = data2.iloc[:, :-1]\n",
    "\n",
    "# Combine the datasets and labels\n",
    "data = pd.concat([data1, data2], axis=1)\n",
    "label = label1\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (X_train.shape[1],)\n",
    "\n",
    "# Define the attention mechanism layer\n",
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, features, hidden):\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "\n",
    "        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
    "\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "# Define the model architecture with attention mechanism\n",
    "def create_model(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(inputs)\n",
    "    hidden = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "    context_vector, attention_weights = Attention(32)(x, hidden)\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid')(context_vector)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "model = create_model(input_shape)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=40, batch_size=8, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the test accuracy\n",
    "print('Test accuracy:', accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/homebrew/lib/python3.10/site-packages (1.0.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/homebrew/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/homebrew/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /opt/homebrew/lib/python3.10/site-packages (from tensorflow) (1.23.3)\n",
      "Requirement already satisfied: protobuf>=3.1.0 in /opt/homebrew/lib/python3.10/site-packages (from tensorflow) (4.21.6)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 94.9657 - accuracy: 0.5833 - val_loss: 56.6671 - val_accuracy: 0.6296\n",
      "Epoch 2/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 100.5313 - accuracy: 0.5880 - val_loss: 38.8681 - val_accuracy: 0.7222\n",
      "Epoch 3/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 103.7728 - accuracy: 0.5324 - val_loss: 36.4857 - val_accuracy: 0.6667\n",
      "Epoch 4/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 90.8195 - accuracy: 0.5370 - val_loss: 45.1882 - val_accuracy: 0.6852\n",
      "Epoch 5/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 68.2692 - accuracy: 0.5556 - val_loss: 44.9211 - val_accuracy: 0.6852\n",
      "Epoch 6/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 69.4472 - accuracy: 0.5880 - val_loss: 29.1608 - val_accuracy: 0.7778\n",
      "Epoch 7/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 73.4816 - accuracy: 0.5833 - val_loss: 41.4414 - val_accuracy: 0.7037\n",
      "Epoch 8/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 68.1444 - accuracy: 0.5602 - val_loss: 43.5061 - val_accuracy: 0.7037\n",
      "Epoch 9/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 64.0963 - accuracy: 0.5972 - val_loss: 46.6407 - val_accuracy: 0.6481\n",
      "Epoch 10/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 53.6612 - accuracy: 0.5556 - val_loss: 41.4605 - val_accuracy: 0.6852\n",
      "Epoch 11/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 49.3352 - accuracy: 0.5694 - val_loss: 45.2255 - val_accuracy: 0.6481\n",
      "Epoch 12/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 36.4851 - accuracy: 0.6481 - val_loss: 58.5454 - val_accuracy: 0.6481\n",
      "Epoch 13/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 48.2672 - accuracy: 0.5833 - val_loss: 55.3434 - val_accuracy: 0.6481\n",
      "Epoch 14/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 43.0425 - accuracy: 0.5417 - val_loss: 63.3684 - val_accuracy: 0.6481\n",
      "Epoch 15/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 49.3025 - accuracy: 0.5324 - val_loss: 54.9170 - val_accuracy: 0.6296\n",
      "Epoch 16/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 38.9240 - accuracy: 0.6019 - val_loss: 56.9906 - val_accuracy: 0.5370\n",
      "Epoch 17/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 50.6542 - accuracy: 0.5556 - val_loss: 52.6157 - val_accuracy: 0.5741\n",
      "Epoch 18/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 37.7741 - accuracy: 0.5787 - val_loss: 55.0358 - val_accuracy: 0.5926\n",
      "Epoch 19/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 30.8973 - accuracy: 0.5509 - val_loss: 48.6686 - val_accuracy: 0.6296\n",
      "Epoch 20/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 33.9962 - accuracy: 0.5648 - val_loss: 47.2682 - val_accuracy: 0.6296\n",
      "Epoch 21/40\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 39.2929 - accuracy: 0.6435 - val_loss: 60.4250 - val_accuracy: 0.5000\n",
      "Epoch 22/40\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 34.8433 - accuracy: 0.5741 - val_loss: 50.3838 - val_accuracy: 0.6296\n",
      "Epoch 23/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 29.0905 - accuracy: 0.5741 - val_loss: 48.3164 - val_accuracy: 0.5556\n",
      "Epoch 24/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 33.7275 - accuracy: 0.5694 - val_loss: 43.6980 - val_accuracy: 0.6296\n",
      "Epoch 25/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 26.8012 - accuracy: 0.6435 - val_loss: 39.0504 - val_accuracy: 0.5926\n",
      "Epoch 26/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 31.8555 - accuracy: 0.5880 - val_loss: 50.1896 - val_accuracy: 0.5000\n",
      "Epoch 27/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 27.6031 - accuracy: 0.5741 - val_loss: 37.0144 - val_accuracy: 0.6481\n",
      "Epoch 28/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 30.5525 - accuracy: 0.6065 - val_loss: 39.9177 - val_accuracy: 0.5741\n",
      "Epoch 29/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 32.9982 - accuracy: 0.5509 - val_loss: 50.4781 - val_accuracy: 0.5370\n",
      "Epoch 30/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 22.1531 - accuracy: 0.5926 - val_loss: 46.4222 - val_accuracy: 0.5741\n",
      "Epoch 31/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 26.9911 - accuracy: 0.5880 - val_loss: 40.9094 - val_accuracy: 0.5926\n",
      "Epoch 32/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 25.4246 - accuracy: 0.6019 - val_loss: 42.1238 - val_accuracy: 0.5741\n",
      "Epoch 33/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 20.4272 - accuracy: 0.6065 - val_loss: 44.0679 - val_accuracy: 0.6296\n",
      "Epoch 34/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 19.1266 - accuracy: 0.5787 - val_loss: 39.4123 - val_accuracy: 0.6481\n",
      "Epoch 35/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 20.1276 - accuracy: 0.6065 - val_loss: 37.7606 - val_accuracy: 0.6481\n",
      "Epoch 36/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 22.3050 - accuracy: 0.6019 - val_loss: 33.6073 - val_accuracy: 0.6296\n",
      "Epoch 37/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 20.4923 - accuracy: 0.5231 - val_loss: 36.5488 - val_accuracy: 0.5556\n",
      "Epoch 38/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 22.3060 - accuracy: 0.6157 - val_loss: 32.9191 - val_accuracy: 0.6296\n",
      "Epoch 39/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 20.3493 - accuracy: 0.6019 - val_loss: 47.2271 - val_accuracy: 0.4630\n",
      "Epoch 40/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 15.2476 - accuracy: 0.6065 - val_loss: 27.4059 - val_accuracy: 0.6852\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.5630 - accuracy: 0.7593\n",
      "Test accuracy: 0.7592592835426331\n"
     ]
    }
   ],
   "source": [
    "#exclude only\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and prepare the datasets\n",
    "data1 = pd.read_csv(\"../dataset/processed_data/Parkinson_CV_ensemble_excludediag.tab\", delimiter=\"\\t\")\n",
    "data2 = pd.read_csv(\"../dataset/processed_data/Parkinson_FD_ensemble_pca_exclude_diag.tab\", delimiter=\"\\t\")\n",
    "\n",
    "# Filter the last column as the label\n",
    "label1 = data1.iloc[:, -1]\n",
    "label2 = data2.iloc[:, -1]\n",
    "label1 = label1.replace({'Co': 0, 'Pt': 1})\n",
    "label2 = label2.replace({'Co': 0, 'Pt': 1})\n",
    "\n",
    "# Remove the last column from the datasets\n",
    "data1 = data1.iloc[:, :-1]\n",
    "data2 = data2.iloc[:, :-1]\n",
    "\n",
    "# Combine the datasets and labels\n",
    "data = pd.concat([data1, data2], axis=1)\n",
    "label = label1\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (X_train.shape[1],)\n",
    "\n",
    "# Define the attention mechanism layer\n",
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, features, hidden):\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "\n",
    "        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
    "\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "# Define the model architecture with attention mechanism\n",
    "def create_model(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(inputs)\n",
    "    hidden = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "    context_vector, attention_weights = Attention(32)(x, hidden)\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid')(context_vector)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "model = create_model(input_shape)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=40, batch_size=8, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the test accuracy\n",
    "print('Test accuracy:', accuracy)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

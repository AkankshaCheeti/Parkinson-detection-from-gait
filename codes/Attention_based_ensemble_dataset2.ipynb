{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 19744.5371 - accuracy: 0.4464 - val_loss: 8528.4355 - val_accuracy: 0.6667\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9998.6201 - accuracy: 0.6071 - val_loss: 8025.9897 - val_accuracy: 0.6667\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 6553.0142 - accuracy: 0.6429 - val_loss: 3114.7151 - val_accuracy: 0.6000\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 5333.9292 - accuracy: 0.5179 - val_loss: 3014.2295 - val_accuracy: 0.6667\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7734.7017 - accuracy: 0.5179 - val_loss: 5841.5186 - val_accuracy: 0.6000\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 3475.4136 - accuracy: 0.5893 - val_loss: 3758.6584 - val_accuracy: 0.6000\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 6113.2485 - accuracy: 0.4286 - val_loss: 2811.9016 - val_accuracy: 0.6000\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 2374.0859 - accuracy: 0.7321 - val_loss: 6904.7793 - val_accuracy: 0.6000\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 3383.8455 - accuracy: 0.5714 - val_loss: 4025.0986 - val_accuracy: 0.6000\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 3846.2246 - accuracy: 0.5357 - val_loss: 4662.7769 - val_accuracy: 0.6000\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 2327.4626 - accuracy: 0.5357 - val_loss: 4116.2734 - val_accuracy: 0.6000\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 2174.8713 - accuracy: 0.5536 - val_loss: 3894.5085 - val_accuracy: 0.6667\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 3890.3188 - accuracy: 0.5357 - val_loss: 2560.1260 - val_accuracy: 0.6667\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1979.8899 - accuracy: 0.6071 - val_loss: 2031.5747 - val_accuracy: 0.6667\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1825.4148 - accuracy: 0.4821 - val_loss: 1352.6603 - val_accuracy: 0.7333\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1508.6324 - accuracy: 0.6607 - val_loss: 1898.6638 - val_accuracy: 0.6667\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 3090.7944 - accuracy: 0.6786 - val_loss: 1115.6628 - val_accuracy: 0.7333\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1690.3457 - accuracy: 0.6071 - val_loss: 1919.9731 - val_accuracy: 0.6667\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 2604.5723 - accuracy: 0.5714 - val_loss: 781.0627 - val_accuracy: 0.4000\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 2279.2397 - accuracy: 0.6071 - val_loss: 2395.0657 - val_accuracy: 0.6000\n",
      "Epoch 21/30\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1540.6843 - accuracy: 0.6607 - val_loss: 775.1813 - val_accuracy: 0.6667\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 2018.3088 - accuracy: 0.5714 - val_loss: 1283.3893 - val_accuracy: 0.6000\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1388.3411 - accuracy: 0.6071 - val_loss: 1451.2227 - val_accuracy: 0.6000\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1066.8483 - accuracy: 0.5536 - val_loss: 2193.2280 - val_accuracy: 0.2667\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 2597.2319 - accuracy: 0.5357 - val_loss: 3484.9058 - val_accuracy: 0.6000\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 2028.9121 - accuracy: 0.6786 - val_loss: 4212.6362 - val_accuracy: 0.6000\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 3464.1875 - accuracy: 0.4821 - val_loss: 2345.5056 - val_accuracy: 0.2667\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 2515.1379 - accuracy: 0.5536 - val_loss: 2277.8054 - val_accuracy: 0.6000\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 3029.2788 - accuracy: 0.5536 - val_loss: 1597.2742 - val_accuracy: 0.4667\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1707.7966 - accuracy: 0.4821 - val_loss: 1864.4554 - val_accuracy: 0.6000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1031.9022 - accuracy: 0.6000\n",
      "Test accuracy: 0.6000000238418579\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and prepare the datasets\n",
    "data1 = pd.read_csv(\"../dataset/processed_data/Parkinson_CV_dataset2_ensemble.tab\", delimiter=\"\\t\")\n",
    "data2 = pd.read_csv(\"../dataset/processed_data/Parkinson_FD_dataset2_ensemble_pca.tab\", delimiter=\"\\t\")\n",
    "\n",
    "# Filter the last column as the label\n",
    "label1 = data1.iloc[:, -1]\n",
    "label2 = data2.iloc[:, -1]\n",
    "label1 = label1.replace({'Co': 0, 'Pt': 1})\n",
    "label2 = label2.replace({'Co': 0, 'Pt': 1})\n",
    "\n",
    "# Remove the last column from the datasets\n",
    "data1 = data1.iloc[:, :-1]\n",
    "data2 = data2.iloc[:, :-1]\n",
    "\n",
    "# Combine the datasets and labels\n",
    "data = pd.concat([data1, data2], axis=1)\n",
    "label = label1\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (X_train.shape[1],)\n",
    "\n",
    "# Define the attention mechanism layer\n",
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, features, hidden):\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "\n",
    "        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
    "\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "# Define the model architecture with attention mechanism\n",
    "def create_model(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(inputs)\n",
    "    hidden = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "    context_vector, attention_weights = Attention(32)(x, hidden)\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid')(context_vector)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "model = create_model(input_shape)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=4, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the test accuracy\n",
    "print('Test accuracy:', accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

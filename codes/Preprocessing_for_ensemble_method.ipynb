{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory_path = '../dataset/'\n",
    "output_file = '../dataset/processed_data/Sequence_dataset1.tab'\n",
    "cols=['time', 'l1','l2','l3','l4','l5','l6','l7','l8','r1','r2','r3','r4','r5','r6','r7','r8','total_l','total_r']\n",
    "\n",
    "# Open output file for writing\n",
    "with open(output_file, 'w') as outfile:\n",
    "    \n",
    "    # Write header row to output file\n",
    "    outfile.write('Entry\\n')\n",
    "    \n",
    "    # Loop through directory and process each file\n",
    "    for filename in os.listdir(directory_path):\n",
    "        \n",
    "        # Select only files with .txt extension\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            df = pd.read_csv(file_path, delimiter='\\t', header=None, names=cols)\n",
    "            if(len(df)>8000):\n",
    "                name = filename\n",
    "                outfile.write(f'{name}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"../dataset/processed_data/Sequence_dataset1.tab\"\n",
    "\n",
    "df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "df = df['Entry']\n",
    "\n",
    "filename_sequence = df.values.tolist()\n",
    "# print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cv(df):\n",
    "    cv = df.std() / df.mean()\n",
    "    return cv.tolist()\n",
    "\n",
    "def find_label(filename):\n",
    "    label = filename.split('_')[0][2:4]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "result_directory ='../dataset/processed_data/'\n",
    "directory_path = '../dataset/'\n",
    "cols=['time', 'l1','l2','l3','l4','l5','l6','l7','l8','r1','r2','r3','r4','r5','r6','r7','r8','total_l','total_r']\n",
    "filtered_cols = ['l1','l2','l3','l4','l5','l6','l7','l8','r1','r2','r3','r4','r5','r6','r7','r8']\n",
    "\n",
    "with open(result_directory+'Parkinson_CV_ensemble.tab', 'w', newline='') as file:\n",
    "    writer = csv.writer(file, delimiter='\\t')\n",
    "    header = filtered_cols + ['label']\n",
    "    writer.writerow(header)\n",
    "    for filename in filename_sequence:\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        df = pd.read_csv(file_path, delimiter='\\t', header=None, names=cols)\n",
    "        df_new = df[filtered_cols]\n",
    "        cv = calculate_cv(df_new)\n",
    "        writer.writerow(list(cv) + [find_label(filename)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "def transform_into_frequency_domain(time_series_data,col_len):\n",
    "    # Define the number of samples in the time series\n",
    "    N = 8000\n",
    "\n",
    "    # Compute the discrete Fourier transform of the time series data using np.fft.fft()\n",
    "    fft_result = np.fft.fft(time_series_data)\n",
    "\n",
    "    # Since the force data are real values, we only use the modulus of the frequencies\n",
    "    mod_fft_result = np.abs(fft_result[:N//2])\n",
    "\n",
    "    # Keep only k = 0, 1, ..., 3999 values\n",
    "    mod_fft_result = mod_fft_result[:4000]\n",
    "\n",
    "    # Reshape the result into a 16x4000 array to represent each patient's frequency domain representation\n",
    "    freq_domain_data = mod_fft_result.reshape((col_len, 4000))\n",
    "    return freq_domain_data.tolist()[0]\n",
    "\n",
    "    \n",
    "def find_label(filename):\n",
    "    label = filename.split('_')[0][2:4]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "result_directory ='../dataset/processed_data/'\n",
    "directory_path = '../dataset/'\n",
    "cols=['time', 'l1','l2','l3','l4','l5','l6','l7','l8','r1','r2','r3','r4','r5','r6','r7','r8','total_l','total_r']\n",
    "filtered_cols = ['l1','l2','l3','l4','l5','l6','l7','l8','r1','r2','r3','r4','r5','r6','r7','r8']\n",
    "\n",
    "with open(result_directory+'Parkinson_FD_ensemble.tab', 'w', newline='') as file:\n",
    "    writer = csv.writer(file, delimiter='\\t')\n",
    "    for filename in filename_sequence:\n",
    "        res =[]\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        df = pd.read_csv(file_path, delimiter='\\t', header=None, names=cols)\n",
    "        df_new = df[filtered_cols]\n",
    "        filtered_df = df_new.iloc[:8000, :]\n",
    "        res =transform_into_frequency_domain(filtered_df,16)\n",
    "        print(len(res))\n",
    "        res.append(find_label(filename))\n",
    "        writer.writerow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270, 17)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "result_file = '../dataset/processed_data/Parkinson_FD_ensemble.tab'\n",
    "\n",
    "# Read in the original DataFrame\n",
    "df = pd.read_csv(result_file, delimiter='\\t', header=None)\n",
    "\n",
    "# Separate the label column from the rest of the data\n",
    "label_col = df.iloc[:, -1]\n",
    "df_features = df.iloc[:, :-1]\n",
    "\n",
    "# Perform PCA on the data to reduce the number of components\n",
    "pca = PCA(n_components=16)\n",
    "df_pca = pd.DataFrame(pca.fit_transform(df_features))\n",
    "\n",
    "# Add the label column back to the DataFrame\n",
    "df_pca['label'] = label_col.values\n",
    "\n",
    "# Print the new shape of the DataFrame\n",
    "print(df_pca.shape)\n",
    "df_pca.to_csv('../dataset/processed_data/Parkinson_FD_ensemble_pca.tab', sep='\\t', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
